---
title: "最小二乗法と最尤法"
author: "masuda atsuki"
date: "2/5/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 標本平均と最小二乗法
繰り返し測定モデルを考える。
$$
X_i = \mu+E_i\\
E(E_i)=0\\
{\rm Cov}(E_iE_j) =\sigma^2 I_{ij} 
$$
データ$x_1,\cdots,x_n$が与えられたとき、期待値$E(X_i)=\mu$を推定することを考える。
素朴に考えると標本平均を推定量と利用することが多い。上記の状況で標本平均を推定値として採用することは、最小二乗法を利用したことになる。実際、
$$
\frac{\partial}{\partial a}\sum_i(x_i-a)^2=0\\
a=\frac{1}{n}\sum_ix_i
$$
となり、最小二乗法による推定値は標本平均となる

#### 標本平均の性質
標本平均は以下の性質を持ち、代標本では期待値に対して十分な精度が期待できる
$$\begin{align}
E\left(\frac{1}{n}\sum_i X_i\right)&=\mu\hspace{3em} 
(E_iの期待値は0) 
\tag{1}\\ 
V\left(\frac{1}{n}\sum_i X_i\right)&=\frac{1}{n^2}\sum_i V (X_i) \hspace{3em} 
(独立性から和を外に出した)\\ 
&=\frac{n\sigma^2}{n^2} \hspace{3em} 
(分散はiによらないため和は\sigma の n倍になる) \\
&=\frac{\sigma^2}{n}
\tag{2}
\end{align}
$$
(1)より不偏推定量だとわかり、(2)からチェビシェフの不等式を用いると期待値$\mu$に確率収束することがわかる

### 標本平均と最尤法
標本平均の利用はもっとも素朴な推論だが、仮に$E$の分布がわかっている場合、最尤法による期待値の推定を行うことができる。
$$\begin{align}
a = \arg\min_{\mu_i}\left( \sum_i\log (f(x_i|\mu_i)) \right)=\arg\min_{\mu}\sum_i\log (f(x_i|\mu))
\end{align}
$$
$E$の分布がガウス分布であるとき、最小二乗法と尤度推定法の結果は同一になる。また、最尤法には適切な正則条件(*)のもとで次の性質が知られている。

1. 一致推定量 である
2. 一般には不偏推定量**ではない**
3. 漸近正規性をもつ
4. 漸近的有効推定量である

2については、3の性質から実質的に不偏推定量とし扱われ問題視されていない。また加えて4の性質を持つことから、大標本では実質的な有効推定量として見なし、その意味でもっとも良い推定量とされることが多い。

(*)次のような性質のことを指すよう。よくわかっていない

- 密度関数が存在する
- 分布のサポート（定義域）がパラメータに依らない
- パラメータの微分と確率変数の積分が交換できる
- スコア関数を確率変数としたとき、適当な字数までのモーメントが存在する
-フィッシャー情報行列が正定値である


```{r cars}
summary(cars)
```
